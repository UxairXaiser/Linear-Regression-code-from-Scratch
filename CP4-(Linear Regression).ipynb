{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0,5,0.1, dtype=np.float32)\n",
    "delta = np.random.uniform(-1,1, size=X.shape[0])\n",
    "Y = .4 * X + 3 + delta\n",
    "\n",
    "#making a copy for later use\n",
    "rx = X\n",
    "\n",
    "ry = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.1        0.2        0.3        0.4        0.5\n",
      " 0.6        0.7        0.8        0.90000004 1.         1.1\n",
      " 1.2        1.3000001  1.4        1.5        1.6        1.7\n",
      " 1.8000001  1.9        2.         2.1000001  2.2        2.3\n",
      " 2.4        2.5        2.6000001  2.7        2.8        2.9\n",
      " 3.         3.1000001  3.2        3.3        3.4        3.5\n",
      " 3.6000001  3.7        3.8        3.9        4.         4.1\n",
      " 4.2000003  4.3        4.4        4.5        4.6        4.7000003\n",
      " 4.8        4.9       ]\n",
      "[2.59278858 2.44299905 3.4950303  3.02705034 3.26802957 3.3949996\n",
      " 3.29403122 2.51921912 3.97264267 4.21378814 2.54324146 3.30561201\n",
      " 2.50243112 4.46607658 4.25189705 4.08538845 3.4251335  4.64883191\n",
      " 3.30230054 4.13044757 3.42098869 3.56953108 4.05651678 4.43139619\n",
      " 4.27172454 4.40411734 4.32003897 3.6981756  4.9058807  4.45557663\n",
      " 3.56604865 3.79893419 3.4701991  4.68471448 3.5008237  4.60181891\n",
      " 4.78342926 4.07684452 5.18709618 3.83732293 5.56805124 3.69150569\n",
      " 5.19455633 5.32529517 3.86334771 5.76294831 4.16092045 4.20572258\n",
      " 4.82571547 5.73705147]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)\n",
    "#Calculating Yp\n",
    "def predicting_Yp(X, w, b):\n",
    "    Yp = []  \n",
    "    for i in X:\n",
    "        Yp.append((w * i) + b)\n",
    "    return Yp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating loss using MSE\n",
    "def calculate_loss(X, Y, Yp):\n",
    "    loss = 0 \n",
    "    for i in range(len(X)):\n",
    "        loss += (Y[i] - Yp[i])**2\n",
    "    loss = loss / len(Y)\n",
    "    return loss\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization using SGD\n",
    "def updating_param(X,Y,Yp,lr,w,b):\n",
    "\n",
    "    #Updating weight\n",
    "    sgd = 0\n",
    "    for i in range(0,len(X)):\n",
    "        sgd += X[i]*(Y[i] - Yp[i])\n",
    "\n",
    "    sgd = (-2*sgd)/len(Y)\n",
    "    w = w -(lr*sgd)\n",
    "\n",
    "    #Updating Bais\n",
    "    sgd = 0\n",
    "    for i in range(0,len(X)):\n",
    "        sgd += (Y[i] - Yp[i])\n",
    "\n",
    "    sgd = (-2*sgd)/len(Y)\n",
    "    b = b -(lr*sgd)\n",
    "\n",
    "    return w,b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test prediction for a single input value\n",
    "def test_value(x, w, b):\n",
    "    \"\"\"Returns the predicted value for a single input x.\"\"\"\n",
    "    return (w * x) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on iteration 0 is: 3.5411599052112077\n",
      "Loss on iteration 1 is: 2.949804842710122\n",
      "Loss on iteration 2 is: 2.53447129133751\n",
      "Loss on iteration 3 is: 2.2294374525580083\n",
      "Loss on iteration 4 is: 1.9951960933042932\n",
      "Loss on iteration 5 is: 1.8078303192399447\n",
      "Loss on iteration 6 is: 1.6527108912774309\n",
      "Loss on iteration 7 is: 1.5207557855259082\n",
      "Loss on iteration 8 is: 1.4062090415527928\n",
      "Loss on iteration 9 is: 1.305320597848653\n",
      "Loss on iteration 10 is: 1.2155605522934598\n",
      "Loss on iteration 11 is: 1.135150519654415\n",
      "Loss on iteration 12 is: 1.0627832271514281\n",
      "Loss on iteration 13 is: 0.9974539361511703\n",
      "Loss on iteration 14 is: 0.9383583709566526\n",
      "Loss on iteration 15 is: 0.8848302696020919\n",
      "Loss on iteration 16 is: 0.8363026010647415\n",
      "Loss on iteration 17 is: 0.7922829739933483\n",
      "Loss on iteration 18 is: 0.7523376053235578\n",
      "Loss on iteration 19 is: 0.716080496817005\n",
      "Loss on iteration 20 is: 0.6831658201941164\n",
      "Loss on iteration 21 is: 0.6532823145027138\n",
      "Loss on iteration 22 is: 0.6261489763928002\n",
      "Loss on iteration 23 is: 0.601511607681852\n",
      "Loss on iteration 24 is: 0.5791399536262842\n",
      "Loss on iteration 25 is: 0.5588252662843731\n",
      "Loss on iteration 26 is: 0.5403781879078539\n",
      "Loss on iteration 27 is: 0.5236268858276316\n",
      "Loss on iteration 28 is: 0.5084153925277811\n",
      "Loss on iteration 29 is: 0.49460211830115525\n",
      "Loss on iteration 30 is: 0.48205851247477244\n",
      "Loss on iteration 31 is: 0.4706678547185353\n",
      "Loss on iteration 32 is: 0.46032416161717654\n",
      "Loss on iteration 33 is: 0.4509311962135935\n",
      "Loss on iteration 34 is: 0.44240157005281483\n",
      "Loss on iteration 35 is: 0.43465592862803015\n",
      "Loss on iteration 36 is: 0.4276222122093197\n",
      "Loss on iteration 37 is: 0.42123498491680583\n",
      "Loss on iteration 38 is: 0.41543482564142004\n",
      "Loss on iteration 39 is: 0.41016777505503393\n",
      "Loss on iteration 40 is: 0.40538483351094995\n",
      "Loss on iteration 41 is: 0.40104150513139986\n",
      "Loss on iteration 42 is: 0.3970973838215259\n",
      "Loss on iteration 43 is: 0.39351577734717397\n",
      "Loss on iteration 44 is: 0.3902633659725575\n",
      "Loss on iteration 45 is: 0.3873098924781043\n",
      "Loss on iteration 46 is: 0.3846278806723549\n",
      "Loss on iteration 47 is: 0.38219237977782217\n",
      "Loss on iteration 48 is: 0.37998073231200236\n",
      "Loss on iteration 49 is: 0.3779723633036435\n",
      "Loss on iteration 50 is: 0.3761485888830481\n",
      "Loss on iteration 51 is: 0.37449244246556007\n",
      "Loss on iteration 52 is: 0.3729885169111129\n",
      "Loss on iteration 53 is: 0.37162282119138923\n",
      "Loss on iteration 54 is: 0.3703826502311258\n",
      "Loss on iteration 55 is: 0.3692564667126821\n",
      "Loss on iteration 56 is: 0.36823379374428045\n",
      "Loss on iteration 57 is: 0.36730511739340643\n",
      "Loss on iteration 58 is: 0.36646179817862984\n",
      "Loss on iteration 59 is: 0.3656959906964552\n",
      "Loss on iteration 60 is: 0.3650005706354835\n",
      "Loss on iteration 61 is: 0.36436906849890144\n",
      "Loss on iteration 62 is: 0.3637956094187141\n",
      "Loss on iteration 63 is: 0.3632748585018131\n",
      "Loss on iteration 64 is: 0.3628019711994361\n",
      "Loss on iteration 65 is: 0.36237254823830056\n",
      "Loss on iteration 66 is: 0.36198259469413996\n",
      "Loss on iteration 67 is: 0.3616284828269\n",
      "Loss on iteration 68 is: 0.3613069183318515\n",
      "Loss on iteration 69 is: 0.3610149096926564\n",
      "Loss on iteration 70 is: 0.3607497403512717\n",
      "Loss on iteration 71 is: 0.36050894343579637\n",
      "Loss on iteration 72 is: 0.3602902788111464\n",
      "Loss on iteration 73 is: 0.36009171223906733\n",
      "Loss on iteration 74 is: 0.3599113964536016\n",
      "Loss on iteration 75 is: 0.3597476539759644\n",
      "Loss on iteration 76 is: 0.3595989615089493\n",
      "Loss on iteration 77 is: 0.35946393576568364\n",
      "Loss on iteration 78 is: 0.35934132060090485\n",
      "Loss on iteration 79 is: 0.35922997532503315\n",
      "Loss on iteration 80 is: 0.35912886409232914\n",
      "Loss on iteration 81 is: 0.3590370462644163\n",
      "Loss on iteration 82 is: 0.35895366765951553\n",
      "Loss on iteration 83 is: 0.35887795260598815\n",
      "Loss on iteration 84 is: 0.3588091967262579\n",
      "Loss on iteration 85 is: 0.3587467603839815\n",
      "Loss on iteration 86 is: 0.35869006273350945\n",
      "Loss on iteration 87 is: 0.3586385763162748\n",
      "Loss on iteration 88 is: 0.3585918221538433\n",
      "Loss on iteration 89 is: 0.35854936529197395\n",
      "Loss on iteration 90 is: 0.3585108107542376\n",
      "Loss on iteration 91 is: 0.3584757998675492\n",
      "Loss on iteration 92 is: 0.3584440069254289\n",
      "Loss on iteration 93 is: 0.358415136157955\n",
      "Loss on iteration 94 is: 0.35838891898021147\n",
      "Loss on iteration 95 is: 0.3583651114936442\n",
      "Loss on iteration 96 is: 0.358343492217069\n",
      "Loss on iteration 97 is: 0.3583238600262324\n",
      "Loss on iteration 98 is: 0.3583060322827503\n",
      "Loss on iteration 99 is: 0.3582898431350233\n",
      "Loss on iteration 100 is: 0.3582751419753172\n",
      "Loss on iteration 101 is: 0.35826179203865927\n",
      "Loss on iteration 102 is: 0.35824966913051215\n",
      "Loss on iteration 103 is: 0.35823866047139213\n",
      "Loss on iteration 104 is: 0.35822866364768\n",
      "Loss on iteration 105 is: 0.3582195856588678\n",
      "Loss on iteration 106 is: 0.35821134205237365\n",
      "Loss on iteration 107 is: 0.35820385613787914\n",
      "Loss on iteration 108 is: 0.3581970582738789\n",
      "Loss on iteration 109 is: 0.3581908852198049\n",
      "Loss on iteration 110 is: 0.3581852795477001\n",
      "Loss on iteration 111 is: 0.3581801891079646\n",
      "Loss on iteration 112 is: 0.35817556654420857\n",
      "Loss on iteration 113 is: 0.3581713688526946\n",
      "Loss on iteration 114 is: 0.358167556982275\n",
      "Loss on iteration 115 is: 0.35816409547109684\n",
      "Loss on iteration 116 is: 0.3581609521167023\n",
      "Loss on iteration 117 is: 0.35815809767644713\n",
      "Loss on iteration 118 is: 0.3581555055954577\n",
      "Loss on iteration 119 is: 0.35815315175958923\n",
      "Loss on iteration 120 is: 0.3581510142710933\n",
      "Loss on iteration 121 is: 0.35814907324490247\n",
      "Loss on iteration 122 is: 0.35814731062363864\n",
      "Loss on iteration 123 is: 0.3581457100096263\n",
      "Loss on iteration 124 is: 0.358144256512344\n",
      "Loss on iteration 125 is: 0.3581429366098984\n",
      "Loss on iteration 126 is: 0.35814173802322913\n",
      "Loss on iteration 127 is: 0.35814064960187786\n",
      "Loss on iteration 128 is: 0.3581396612202543\n",
      "Loss on iteration 129 is: 0.35813876368343883\n",
      "Loss on iteration 130 is: 0.3581379486416412\n",
      "Loss on iteration 131 is: 0.3581372085125226\n",
      "Loss on iteration 132 is: 0.3581365364106582\n",
      "Loss on iteration 133 is: 0.3581359260834799\n",
      "Loss on iteration 134 is: 0.35813537185311084\n",
      "Loss on iteration 135 is: 0.35813486856354243\n",
      "Loss on iteration 136 is: 0.35813441153266945\n",
      "Loss on iteration 137 is: 0.3581339965087305\n",
      "Loss on iteration 138 is: 0.35813361963075585\n",
      "Loss on iteration 139 is: 0.35813327739264744\n",
      "Loss on iteration 140 is: 0.35813296661056204\n",
      "Loss on iteration 141 is: 0.3581326843932925\n",
      "Loss on iteration 142 is: 0.3581324281153695\n",
      "Loss on iteration 143 is: 0.3581321953926384\n",
      "Loss on iteration 144 is: 0.3581319840600781\n",
      "Loss on iteration 145 is: 0.35813179215166074\n",
      "Loss on iteration 146 is: 0.35813161788206105\n",
      "Loss on iteration 147 is: 0.35813145963004805\n",
      "Loss on iteration 148 is: 0.3581313159234022\n",
      "Loss on iteration 149 is: 0.35813118542522027\n",
      "Loss on iteration 150 is: 0.3581310669214761\n",
      "Loss on iteration 151 is: 0.35813095930972927\n",
      "Loss on iteration 152 is: 0.35813086158886703\n",
      "Loss on iteration 153 is: 0.3581307728497914\n",
      "Loss on iteration 154 is: 0.3581306922669624\n",
      "Loss on iteration 155 is: 0.35813061909071764\n",
      "Loss on iteration 156 is: 0.35813055264029786\n",
      "Loss on iteration 157 is: 0.3581304922975146\n",
      "Loss on iteration 158 is: 0.35813043750099843\n",
      "Loss on iteration 159 is: 0.35813038774097705\n",
      "Loss on iteration 160 is: 0.35813034255453297\n",
      "Loss on iteration 161 is: 0.35813030152129616\n",
      "Loss on iteration 162 is: 0.3581302642595343\n",
      "Loss on iteration 163 is: 0.35813023042260106\n",
      "Loss on iteration 164 is: 0.3581301996957111\n",
      "Loss on iteration 165 is: 0.358130171793012\n",
      "Loss on iteration 166 is: 0.358130146454925\n",
      "Loss on iteration 167 is: 0.3581301234457294\n",
      "Loss on iteration 168 is: 0.35813010255137107\n",
      "Loss on iteration 169 is: 0.3581300835774691\n",
      "Loss on iteration 170 is: 0.3581300663475091\n",
      "Loss on iteration 171 is: 0.35813005070120146\n",
      "Loss on iteration 172 is: 0.3581300364929878\n",
      "Loss on iteration 173 is: 0.35813002359068896\n",
      "Loss on iteration 174 is: 0.3581300118742754\n",
      "Loss on iteration 175 is: 0.35813000123474853\n",
      "Loss on iteration 176 is: 0.3581299915731293\n",
      "Loss on iteration 177 is: 0.3581299827995354\n",
      "Loss on iteration 178 is: 0.3581299748323461\n",
      "Loss on iteration 179 is: 0.3581299675974424\n",
      "Loss on iteration 180 is: 0.3581299610275184\n",
      "Loss on iteration 181 is: 0.3581299550614535\n",
      "Loss on iteration 182 is: 0.35812994964374567\n",
      "Loss on iteration 183 is: 0.3581299447239942\n",
      "Loss on iteration 184 is: 0.35812994025643\n",
      "Loss on iteration 185 is: 0.35812993619949146\n",
      "Loss on iteration 186 is: 0.3581299325154374\n",
      "Loss on iteration 187 is: 0.35812992916999437\n",
      "Loss on iteration 188 is: 0.3581299261320401\n",
      "Loss on iteration 189 is: 0.3581299233733125\n",
      "Loss on iteration 190 is: 0.35812992086814677\n",
      "Loss on iteration 191 is: 0.3581299185932375\n",
      "Loss on iteration 192 is: 0.35812991652742143\n",
      "Loss on iteration 193 is: 0.35812991465147986\n",
      "Loss on iteration 194 is: 0.3581299129479612\n",
      "Loss on iteration 195 is: 0.3581299114010175\n",
      "Loss on iteration 196 is: 0.35812990999625766\n",
      "Loss on iteration 197 is: 0.358129908720613\n",
      "Loss on iteration 198 is: 0.35812990756221624\n",
      "Loss on iteration 199 is: 0.3581299065102909\n",
      "Loss on iteration 200 is: 0.3581299055550508\n",
      "Loss on iteration 201 is: 0.35812990468760936\n",
      "Loss on iteration 202 is: 0.35812990389989674\n",
      "Loss on iteration 203 is: 0.358129903184585\n",
      "Loss on iteration 204 is: 0.3581299025350194\n",
      "Loss on iteration 205 is: 0.35812990194515737\n",
      "Loss on iteration 206 is: 0.35812990140951073\n",
      "Loss on iteration 207 is: 0.35812990092309704\n",
      "Loss on iteration 208 is: 0.358129900481391\n",
      "Loss on iteration 209 is: 0.3581299000802832\n",
      "Loss on iteration 210 is: 0.35812989971604237\n",
      "Loss on iteration 211 is: 0.3581298993852798\n",
      "Loss on iteration 212 is: 0.3581298990849187\n",
      "Loss on iteration 213 is: 0.3581298988121644\n",
      "Loss on iteration 214 is: 0.35812989856447985\n",
      "Loss on iteration 215 is: 0.35812989833956044\n",
      "Loss on iteration 216 is: 0.35812989813531426\n",
      "Loss on iteration 217 is: 0.3581298979498406\n",
      "Loss on iteration 218 is: 0.35812989778141435\n",
      "Loss on iteration 219 is: 0.3581298976284688\n",
      "Loss on iteration 220 is: 0.3581298974895808\n",
      "Loss on iteration 221 is: 0.3581298973634584\n",
      "Loss on iteration 222 is: 0.3581298972489283\n",
      "Loss on iteration 223 is: 0.35812989714492494\n",
      "Loss on iteration 224 is: 0.3581298970504806\n",
      "Loss on iteration 225 is: 0.35812989696471703\n",
      "Loss on iteration 226 is: 0.3581298968868363\n",
      "Loss on iteration 227 is: 0.3581298968161137\n",
      "Loss on iteration 228 is: 0.35812989675189144\n",
      "Loss on iteration 229 is: 0.35812989669357215\n",
      "Loss on iteration 230 is: 0.358129896640613\n",
      "Loss on iteration 231 is: 0.3581298965925216\n",
      "Loss on iteration 232 is: 0.3581298965488501\n",
      "Loss on iteration 233 is: 0.3581298965091928\n",
      "Loss on iteration 234 is: 0.3581298964731804\n",
      "Loss on iteration 235 is: 0.35812989644047805\n",
      "Loss on iteration 236 is: 0.3581298964107814\n",
      "Loss on iteration 237 is: 0.3581298963838144\n",
      "Loss on iteration 238 is: 0.35812989635932596\n",
      "Loss on iteration 239 is: 0.3581298963370881\n",
      "Loss on iteration 240 is: 0.3581298963168946\n",
      "Loss on iteration 241 is: 0.35812989629855685\n",
      "Loss on iteration 242 is: 0.35812989628190467\n",
      "Loss on iteration 243 is: 0.35812989626678293\n",
      "Loss on iteration 244 is: 0.35812989625305114\n",
      "Loss on iteration 245 is: 0.3581298962405816\n",
      "Loss on iteration 246 is: 0.35812989622925806\n",
      "Loss on iteration 247 is: 0.3581298962189753\n",
      "Loss on iteration 248 is: 0.35812989620963764\n",
      "Loss on iteration 249 is: 0.35812989620115815\n",
      "Loss on iteration 250 is: 0.35812989619345814\n",
      "Loss on iteration 251 is: 0.35812989618646573\n",
      "Loss on iteration 252 is: 0.35812989618011615\n",
      "Loss on iteration 253 is: 0.3581298961743501\n",
      "Loss on iteration 254 is: 0.358129896169114\n",
      "Loss on iteration 255 is: 0.3581298961643592\n",
      "Loss on iteration 256 is: 0.3581298961600416\n",
      "Loss on iteration 257 is: 0.35812989615612045\n",
      "Loss on iteration 258 is: 0.3581298961525601\n",
      "Loss on iteration 259 is: 0.3581298961493269\n",
      "Loss on iteration 260 is: 0.35812989614639074\n",
      "Loss on iteration 261 is: 0.3581298961437245\n",
      "Loss on iteration 262 is: 0.35812989614130347\n",
      "Loss on iteration 263 is: 0.35812989613910473\n",
      "Loss on iteration 264 is: 0.3581298961371082\n",
      "Loss on iteration 265 is: 0.358129896135295\n",
      "Loss on iteration 266 is: 0.35812989613364865\n",
      "Loss on iteration 267 is: 0.35812989613215357\n",
      "Loss on iteration 268 is: 0.35812989613079593\n",
      "Loss on iteration 269 is: 0.35812989612956314\n",
      "Loss on iteration 270 is: 0.3581298961284435\n",
      "Loss on iteration 271 is: 0.35812989612742696\n",
      "Loss on iteration 272 is: 0.3581298961265038\n",
      "Loss on iteration 273 is: 0.35812989612566526\n",
      "Loss on iteration 274 is: 0.358129896124904\n",
      "Loss on iteration 275 is: 0.3581298961242128\n",
      "Loss on iteration 276 is: 0.3581298961235849\n",
      "Loss on iteration 277 is: 0.35812989612301493\n",
      "Loss on iteration 278 is: 0.35812989612249724\n",
      "Loss on iteration 279 is: 0.35812989612202706\n",
      "Loss on iteration 280 is: 0.3581298961216002\n",
      "Loss on iteration 281 is: 0.35812989612121265\n",
      "Loss on iteration 282 is: 0.3581298961208605\n",
      "Loss on iteration 283 is: 0.3581298961205409\n",
      "Loss on iteration 284 is: 0.3581298961202506\n",
      "Loss on iteration 285 is: 0.35812989611998686\n",
      "Loss on iteration 286 is: 0.35812989611974755\n",
      "Loss on iteration 287 is: 0.35812989611953017\n",
      "Loss on iteration 288 is: 0.3581298961193326\n",
      "Loss on iteration 289 is: 0.3581298961191536\n",
      "Loss on iteration 290 is: 0.35812989611899076\n",
      "Loss on iteration 291 is: 0.3581298961188429\n",
      "Loss on iteration 292 is: 0.35812989611870877\n",
      "Loss on iteration 293 is: 0.3581298961185867\n",
      "Loss on iteration 294 is: 0.3581298961184761\n",
      "Loss on iteration 295 is: 0.35812989611837565\n",
      "Loss on iteration 296 is: 0.35812989611828433\n",
      "Loss on iteration 297 is: 0.35812989611820145\n",
      "Loss on iteration 298 is: 0.3581298961181262\n",
      "Loss on iteration 299 is: 0.35812989611805773\n",
      "Loss on iteration 300 is: 0.35812989611799556\n",
      "Loss on iteration 301 is: 0.3581298961179392\n",
      "Loss on iteration 302 is: 0.3581298961178882\n",
      "Loss on iteration 303 is: 0.35812989611784163\n",
      "Loss on iteration 304 is: 0.3581298961177994\n",
      "Loss on iteration 305 is: 0.35812989611776125\n",
      "Loss on iteration 306 is: 0.3581298961177264\n",
      "Loss on iteration 307 is: 0.3581298961176948\n",
      "Loss on iteration 308 is: 0.3581298961176661\n",
      "Loss on iteration 309 is: 0.35812989611763996\n",
      "Loss on iteration 310 is: 0.3581298961176164\n",
      "Loss on iteration 311 is: 0.35812989611759477\n",
      "Loss on iteration 312 is: 0.3581298961175754\n",
      "Loss on iteration 313 is: 0.3581298961175575\n",
      "Loss on iteration 314 is: 0.3581298961175415\n",
      "Loss on iteration 315 is: 0.35812989611752694\n",
      "Loss on iteration 316 is: 0.35812989611751356\n",
      "Loss on iteration 317 is: 0.3581298961175014\n",
      "Loss on iteration 318 is: 0.3581298961174907\n",
      "Loss on iteration 319 is: 0.3581298961174808\n",
      "Loss on iteration 320 is: 0.35812989611747154\n",
      "Loss on iteration 321 is: 0.35812989611746354\n",
      "Loss on iteration 322 is: 0.3581298961174559\n",
      "Loss on iteration 323 is: 0.3581298961174493\n",
      "Loss on iteration 324 is: 0.3581298961174432\n",
      "Loss on iteration 325 is: 0.3581298961174377\n",
      "Loss on iteration 326 is: 0.35812989611743246\n",
      "Loss on iteration 327 is: 0.3581298961174278\n",
      "Loss on iteration 328 is: 0.3581298961174236\n",
      "Loss on iteration 329 is: 0.3581298961174199\n",
      "Loss on iteration 330 is: 0.3581298961174166\n",
      "Loss on iteration 331 is: 0.35812989611741336\n",
      "Loss on iteration 332 is: 0.3581298961174105\n",
      "Loss on iteration 333 is: 0.3581298961174081\n",
      "Loss on iteration 334 is: 0.35812989611740564\n",
      "Loss on iteration 335 is: 0.35812989611740365\n",
      "Loss on iteration 336 is: 0.3581298961174016\n",
      "Loss on iteration 337 is: 0.35812989611739965\n",
      "Loss on iteration 338 is: 0.3581298961173982\n",
      "Loss on iteration 339 is: 0.3581298961173968\n",
      "Loss on iteration 340 is: 0.35812989611739554\n",
      "Loss on iteration 341 is: 0.3581298961173943\n",
      "Loss on iteration 342 is: 0.35812989611739326\n",
      "Loss on iteration 343 is: 0.3581298961173922\n",
      "Loss on iteration 344 is: 0.35812989611739127\n",
      "Loss on iteration 345 is: 0.35812989611739054\n",
      "Loss on iteration 346 is: 0.3581298961173898\n",
      "Loss on iteration 347 is: 0.35812989611738894\n",
      "Loss on iteration 348 is: 0.35812989611738855\n",
      "Loss on iteration 349 is: 0.35812989611738794\n",
      "Loss on iteration 350 is: 0.35812989611738744\n",
      "Loss on iteration 351 is: 0.35812989611738694\n",
      "Loss on iteration 352 is: 0.3581298961173865\n",
      "Loss on iteration 353 is: 0.3581298961173862\n",
      "Loss on iteration 354 is: 0.35812989611738577\n",
      "Loss on iteration 355 is: 0.3581298961173856\n",
      "Loss on iteration 356 is: 0.3581298961173853\n",
      "Loss on iteration 357 is: 0.358129896117385\n",
      "Loss on iteration 358 is: 0.3581298961173847\n",
      "Loss on iteration 359 is: 0.3581298961173845\n",
      "Loss on iteration 360 is: 0.35812989611738444\n",
      "Loss on iteration 361 is: 0.3581298961173842\n",
      "Loss on iteration 362 is: 0.3581298961173841\n",
      "Loss on iteration 363 is: 0.35812989611738394\n",
      "Loss on iteration 364 is: 0.35812989611738383\n",
      "Loss on iteration 365 is: 0.3581298961173836\n",
      "Loss on iteration 366 is: 0.35812989611738355\n",
      "Loss on iteration 367 is: 0.3581298961173836\n",
      "Loss on iteration 368 is: 0.35812989611738355\n",
      "Loss on iteration 369 is: 0.3581298961173832\n",
      "Loss on iteration 370 is: 0.35812989611738316\n",
      "Loss on iteration 371 is: 0.35812989611738305\n",
      "Loss on iteration 372 is: 0.3581298961173831\n",
      "Loss on iteration 373 is: 0.35812989611738294\n",
      "Loss on iteration 374 is: 0.35812989611738294\n",
      "Loss on iteration 375 is: 0.3581298961173827\n",
      "Loss on iteration 376 is: 0.35812989611738294\n",
      "Loss on iteration 377 is: 0.35812989611738283\n",
      "Loss on iteration 378 is: 0.3581298961173829\n",
      "Loss on iteration 379 is: 0.35812989611738283\n",
      "Loss on iteration 380 is: 0.3581298961173827\n",
      "Loss on iteration 381 is: 0.35812989611738283\n",
      "Loss on iteration 382 is: 0.3581298961173827\n",
      "Loss on iteration 383 is: 0.35812989611738283\n",
      "Loss on iteration 384 is: 0.35812989611738266\n",
      "Loss on iteration 385 is: 0.35812989611738266\n",
      "Loss on iteration 386 is: 0.3581298961173827\n",
      "Loss on iteration 387 is: 0.35812989611738255\n",
      "Loss on iteration 388 is: 0.35812989611738244\n",
      "Loss on iteration 389 is: 0.3581298961173827\n",
      "Loss on iteration 390 is: 0.3581298961173826\n",
      "Loss on iteration 391 is: 0.3581298961173826\n",
      "Loss on iteration 392 is: 0.35812989611738266\n",
      "Loss on iteration 393 is: 0.35812989611738255\n",
      "Loss on iteration 394 is: 0.3581298961173826\n",
      "Loss on iteration 395 is: 0.35812989611738255\n",
      "Loss on iteration 396 is: 0.3581298961173826\n",
      "Loss on iteration 397 is: 0.35812989611738244\n",
      "Loss on iteration 398 is: 0.35812989611738255\n",
      "Loss on iteration 399 is: 0.3581298961173826\n",
      "Loss on iteration 400 is: 0.35812989611738255\n",
      "Loss on iteration 401 is: 0.35812989611738255\n",
      "Loss on iteration 402 is: 0.3581298961173826\n",
      "Loss on iteration 403 is: 0.35812989611738255\n",
      "Loss on iteration 404 is: 0.35812989611738233\n",
      "Loss on iteration 405 is: 0.3581298961173826\n",
      "Loss on iteration 406 is: 0.3581298961173826\n",
      "Loss on iteration 407 is: 0.3581298961173824\n",
      "Loss on iteration 408 is: 0.3581298961173824\n",
      "Loss on iteration 409 is: 0.3581298961173824\n",
      "Loss on iteration 410 is: 0.35812989611738244\n",
      "Loss on iteration 411 is: 0.35812989611738255\n",
      "Loss on iteration 412 is: 0.3581298961173824\n",
      "Loss on iteration 413 is: 0.3581298961173826\n",
      "Loss on iteration 414 is: 0.3581298961173824\n",
      "Loss on iteration 415 is: 0.35812989611738255\n",
      "Loss on iteration 416 is: 0.3581298961173826\n",
      "Loss on iteration 417 is: 0.35812989611738255\n",
      "Loss on iteration 418 is: 0.3581298961173826\n",
      "Loss on iteration 419 is: 0.35812989611738255\n",
      "Loss on iteration 420 is: 0.3581298961173826\n",
      "Loss on iteration 421 is: 0.35812989611738255\n",
      "Loss on iteration 422 is: 0.35812989611738244\n",
      "Loss on iteration 423 is: 0.35812989611738255\n",
      "Loss on iteration 424 is: 0.35812989611738244\n",
      "Loss on iteration 425 is: 0.35812989611738244\n",
      "Loss on iteration 426 is: 0.3581298961173824\n",
      "Loss on iteration 427 is: 0.3581298961173826\n",
      "Loss on iteration 428 is: 0.35812989611738244\n",
      "Loss on iteration 429 is: 0.35812989611738244\n",
      "Loss on iteration 430 is: 0.35812989611738244\n",
      "Loss on iteration 431 is: 0.35812989611738244\n",
      "Loss on iteration 432 is: 0.35812989611738255\n",
      "Loss on iteration 433 is: 0.35812989611738244\n",
      "Loss on iteration 434 is: 0.3581298961173826\n",
      "Loss on iteration 435 is: 0.35812989611738255\n",
      "Loss on iteration 436 is: 0.3581298961173826\n",
      "Loss on iteration 437 is: 0.35812989611738255\n",
      "Loss on iteration 438 is: 0.35812989611738255\n",
      "Loss on iteration 439 is: 0.35812989611738266\n",
      "Loss on iteration 440 is: 0.35812989611738244\n",
      "Loss on iteration 441 is: 0.35812989611738266\n",
      "Loss on iteration 442 is: 0.35812989611738233\n",
      "Loss on iteration 443 is: 0.3581298961173824\n",
      "Loss on iteration 444 is: 0.35812989611738255\n",
      "Loss on iteration 445 is: 0.35812989611738244\n",
      "Loss on iteration 446 is: 0.35812989611738266\n",
      "Loss on iteration 447 is: 0.3581298961173826\n",
      "Loss on iteration 448 is: 0.35812989611738255\n",
      "Loss on iteration 449 is: 0.35812989611738244\n",
      "Loss on iteration 450 is: 0.35812989611738233\n",
      "Loss on iteration 451 is: 0.35812989611738244\n",
      "Loss on iteration 452 is: 0.35812989611738255\n",
      "Loss on iteration 453 is: 0.35812989611738244\n",
      "Loss on iteration 454 is: 0.35812989611738255\n",
      "Loss on iteration 455 is: 0.35812989611738255\n",
      "Loss on iteration 456 is: 0.35812989611738255\n",
      "Loss on iteration 457 is: 0.35812989611738244\n",
      "Loss on iteration 458 is: 0.35812989611738244\n",
      "Loss on iteration 459 is: 0.3581298961173826\n",
      "Loss on iteration 460 is: 0.35812989611738255\n",
      "Loss on iteration 461 is: 0.35812989611738244\n",
      "Loss on iteration 462 is: 0.35812989611738244\n",
      "Loss on iteration 463 is: 0.35812989611738255\n",
      "Loss on iteration 464 is: 0.35812989611738244\n",
      "Loss on iteration 465 is: 0.35812989611738255\n",
      "Loss on iteration 466 is: 0.35812989611738233\n",
      "Loss on iteration 467 is: 0.35812989611738255\n",
      "Loss on iteration 468 is: 0.35812989611738255\n",
      "Loss on iteration 469 is: 0.35812989611738244\n",
      "Loss on iteration 470 is: 0.35812989611738244\n",
      "Loss on iteration 471 is: 0.3581298961173824\n",
      "Loss on iteration 472 is: 0.35812989611738255\n",
      "Loss on iteration 473 is: 0.35812989611738255\n",
      "Loss on iteration 474 is: 0.35812989611738255\n",
      "Loss on iteration 475 is: 0.35812989611738233\n",
      "Loss on iteration 476 is: 0.35812989611738266\n",
      "Loss on iteration 477 is: 0.35812989611738244\n",
      "Loss on iteration 478 is: 0.35812989611738244\n",
      "Loss on iteration 479 is: 0.3581298961173826\n",
      "Loss on iteration 480 is: 0.35812989611738244\n",
      "Loss on iteration 481 is: 0.35812989611738266\n",
      "Loss on iteration 482 is: 0.35812989611738266\n",
      "Loss on iteration 483 is: 0.35812989611738244\n",
      "Loss on iteration 484 is: 0.35812989611738244\n",
      "Loss on iteration 485 is: 0.35812989611738244\n",
      "Loss on iteration 486 is: 0.35812989611738255\n",
      "Loss on iteration 487 is: 0.35812989611738244\n",
      "Loss on iteration 488 is: 0.35812989611738233\n",
      "Loss on iteration 489 is: 0.35812989611738255\n",
      "Loss on iteration 490 is: 0.35812989611738244\n",
      "Loss on iteration 491 is: 0.35812989611738244\n",
      "Loss on iteration 492 is: 0.35812989611738244\n",
      "Loss on iteration 493 is: 0.35812989611738244\n",
      "Loss on iteration 494 is: 0.35812989611738244\n",
      "Loss on iteration 495 is: 0.3581298961173826\n",
      "Loss on iteration 496 is: 0.35812989611738244\n",
      "Loss on iteration 497 is: 0.35812989611738244\n",
      "Loss on iteration 498 is: 0.3581298961173824\n",
      "Loss on iteration 499 is: 0.35812989611738255\n",
      "Loss on iteration 500 is: 0.35812989611738233\n",
      "Loss on iteration 501 is: 0.35812989611738266\n",
      "Loss on iteration 502 is: 0.35812989611738244\n",
      "Loss on iteration 503 is: 0.35812989611738255\n",
      "Loss on iteration 504 is: 0.3581298961173824\n",
      "Loss on iteration 505 is: 0.35812989611738244\n",
      "Loss on iteration 506 is: 0.35812989611738244\n",
      "Loss on iteration 507 is: 0.35812989611738244\n",
      "Loss on iteration 508 is: 0.35812989611738244\n",
      "Loss on iteration 509 is: 0.3581298961173824\n",
      "Loss on iteration 510 is: 0.3581298961173824\n",
      "Loss on iteration 511 is: 0.35812989611738244\n",
      "Loss on iteration 512 is: 0.35812989611738255\n",
      "Loss on iteration 513 is: 0.3581298961173824\n",
      "Loss on iteration 514 is: 0.35812989611738255\n",
      "Loss on iteration 515 is: 0.35812989611738244\n",
      "Loss on iteration 516 is: 0.35812989611738244\n",
      "Loss on iteration 517 is: 0.3581298961173824\n",
      "Loss on iteration 518 is: 0.35812989611738244\n",
      "Loss on iteration 519 is: 0.3581298961173824\n",
      "Loss on iteration 520 is: 0.3581298961173826\n",
      "Loss on iteration 521 is: 0.35812989611738244\n",
      "Loss on iteration 522 is: 0.35812989611738244\n",
      "Loss on iteration 523 is: 0.35812989611738244\n",
      "Loss on iteration 524 is: 0.3581298961173824\n",
      "Loss on iteration 525 is: 0.35812989611738244\n",
      "Loss on iteration 526 is: 0.35812989611738255\n",
      "Loss on iteration 527 is: 0.35812989611738255\n",
      "Loss on iteration 528 is: 0.35812989611738255\n",
      "Loss on iteration 529 is: 0.35812989611738255\n",
      "Loss on iteration 530 is: 0.35812989611738255\n",
      "Loss on iteration 531 is: 0.35812989611738244\n",
      "Loss on iteration 532 is: 0.35812989611738244\n",
      "Loss on iteration 533 is: 0.35812989611738255\n",
      "Loss on iteration 534 is: 0.3581298961173824\n",
      "Loss on iteration 535 is: 0.35812989611738244\n",
      "Loss on iteration 536 is: 0.35812989611738244\n",
      "Loss on iteration 537 is: 0.3581298961173824\n",
      "Loss on iteration 538 is: 0.3581298961173826\n",
      "Loss on iteration 539 is: 0.35812989611738255\n",
      "Loss on iteration 540 is: 0.35812989611738255\n",
      "Loss on iteration 541 is: 0.3581298961173826\n",
      "Loss on iteration 542 is: 0.35812989611738244\n",
      "Loss on iteration 543 is: 0.35812989611738244\n",
      "Loss on iteration 544 is: 0.35812989611738255\n",
      "Loss on iteration 545 is: 0.3581298961173826\n",
      "Loss on iteration 546 is: 0.35812989611738255\n",
      "Loss on iteration 547 is: 0.35812989611738255\n",
      "Loss on iteration 548 is: 0.35812989611738244\n",
      "Loss on iteration 549 is: 0.35812989611738244\n",
      "Loss on iteration 550 is: 0.35812989611738244\n",
      "Loss on iteration 551 is: 0.35812989611738255\n",
      "Loss on iteration 552 is: 0.35812989611738255\n",
      "Loss on iteration 553 is: 0.3581298961173826\n",
      "Loss on iteration 554 is: 0.35812989611738244\n",
      "Loss on iteration 555 is: 0.35812989611738244\n",
      "Loss on iteration 556 is: 0.35812989611738244\n",
      "Loss on iteration 557 is: 0.35812989611738255\n",
      "Loss on iteration 558 is: 0.3581298961173824\n",
      "Loss on iteration 559 is: 0.35812989611738244\n",
      "Loss on iteration 560 is: 0.3581298961173826\n",
      "Loss on iteration 561 is: 0.35812989611738244\n",
      "Loss on iteration 562 is: 0.35812989611738255\n",
      "Loss on iteration 563 is: 0.3581298961173824\n",
      "Loss on iteration 564 is: 0.35812989611738255\n",
      "Loss on iteration 565 is: 0.35812989611738266\n",
      "Loss on iteration 566 is: 0.3581298961173826\n",
      "Loss on iteration 567 is: 0.35812989611738244\n",
      "Loss on iteration 568 is: 0.35812989611738255\n",
      "Loss on iteration 569 is: 0.35812989611738255\n",
      "Loss on iteration 570 is: 0.35812989611738255\n",
      "Loss on iteration 571 is: 0.35812989611738244\n",
      "Loss on iteration 572 is: 0.3581298961173824\n",
      "Loss on iteration 573 is: 0.35812989611738255\n",
      "Loss on iteration 574 is: 0.35812989611738255\n",
      "Loss on iteration 575 is: 0.35812989611738244\n",
      "Loss on iteration 576 is: 0.35812989611738255\n",
      "Loss on iteration 577 is: 0.3581298961173824\n",
      "Loss on iteration 578 is: 0.35812989611738255\n",
      "Loss on iteration 579 is: 0.35812989611738244\n",
      "Loss on iteration 580 is: 0.3581298961173826\n",
      "Loss on iteration 581 is: 0.35812989611738244\n",
      "Loss on iteration 582 is: 0.3581298961173826\n",
      "Loss on iteration 583 is: 0.35812989611738244\n",
      "Loss on iteration 584 is: 0.35812989611738244\n",
      "Loss on iteration 585 is: 0.35812989611738255\n",
      "Loss on iteration 586 is: 0.35812989611738255\n",
      "Loss on iteration 587 is: 0.3581298961173826\n",
      "Loss on iteration 588 is: 0.35812989611738255\n",
      "Loss on iteration 589 is: 0.3581298961173824\n",
      "Loss on iteration 590 is: 0.3581298961173824\n",
      "Loss on iteration 591 is: 0.3581298961173826\n",
      "Loss on iteration 592 is: 0.35812989611738244\n",
      "Loss on iteration 593 is: 0.35812989611738255\n",
      "Loss on iteration 594 is: 0.35812989611738255\n",
      "Loss on iteration 595 is: 0.35812989611738244\n",
      "Loss on iteration 596 is: 0.35812989611738244\n",
      "Loss on iteration 597 is: 0.35812989611738255\n",
      "Loss on iteration 598 is: 0.35812989611738255\n",
      "Loss on iteration 599 is: 0.3581298961173826\n",
      "Loss on iteration 600 is: 0.35812989611738244\n",
      "Loss on iteration 601 is: 0.35812989611738244\n",
      "Loss on iteration 602 is: 0.35812989611738255\n",
      "Loss on iteration 603 is: 0.3581298961173824\n",
      "Loss on iteration 604 is: 0.3581298961173826\n",
      "Loss on iteration 605 is: 0.35812989611738255\n",
      "Loss on iteration 606 is: 0.3581298961173826\n",
      "Loss on iteration 607 is: 0.35812989611738255\n",
      "Loss on iteration 608 is: 0.3581298961173824\n",
      "Loss on iteration 609 is: 0.35812989611738244\n",
      "Loss on iteration 610 is: 0.35812989611738233\n",
      "Loss on iteration 611 is: 0.35812989611738255\n",
      "Loss on iteration 612 is: 0.35812989611738255\n",
      "Loss on iteration 613 is: 0.35812989611738255\n",
      "Loss on iteration 614 is: 0.35812989611738255\n",
      "Loss on iteration 615 is: 0.3581298961173824\n",
      "Loss on iteration 616 is: 0.35812989611738255\n",
      "Loss on iteration 617 is: 0.3581298961173824\n",
      "Loss on iteration 618 is: 0.35812989611738244\n",
      "Loss on iteration 619 is: 0.35812989611738244\n",
      "Loss on iteration 620 is: 0.3581298961173824\n",
      "Loss on iteration 621 is: 0.35812989611738244\n",
      "Loss on iteration 622 is: 0.35812989611738233\n",
      "Loss on iteration 623 is: 0.35812989611738244\n",
      "Loss on iteration 624 is: 0.3581298961173824\n",
      "Loss on iteration 625 is: 0.35812989611738255\n",
      "Loss on iteration 626 is: 0.3581298961173824\n",
      "Loss on iteration 627 is: 0.35812989611738233\n",
      "Loss on iteration 628 is: 0.35812989611738255\n",
      "Loss on iteration 629 is: 0.35812989611738255\n",
      "Loss on iteration 630 is: 0.3581298961173824\n",
      "Loss on iteration 631 is: 0.35812989611738244\n",
      "Loss on iteration 632 is: 0.3581298961173824\n",
      "Loss on iteration 633 is: 0.3581298961173826\n",
      "Loss on iteration 634 is: 0.35812989611738255\n",
      "Loss on iteration 635 is: 0.35812989611738244\n",
      "Loss on iteration 636 is: 0.3581298961173824\n",
      "Loss on iteration 637 is: 0.3581298961173824\n",
      "Loss on iteration 638 is: 0.35812989611738255\n",
      "Loss on iteration 639 is: 0.35812989611738233\n",
      "Loss on iteration 640 is: 0.35812989611738244\n",
      "Loss on iteration 641 is: 0.3581298961173824\n",
      "Loss on iteration 642 is: 0.35812989611738244\n",
      "Loss on iteration 643 is: 0.35812989611738255\n",
      "Loss on iteration 644 is: 0.3581298961173826\n",
      "Loss on iteration 645 is: 0.35812989611738255\n",
      "Loss on iteration 646 is: 0.35812989611738244\n",
      "Loss on iteration 647 is: 0.35812989611738255\n",
      "Loss on iteration 648 is: 0.35812989611738244\n",
      "Loss on iteration 649 is: 0.35812989611738244\n",
      "Loss on iteration 650 is: 0.35812989611738244\n",
      "Loss on iteration 651 is: 0.35812989611738255\n",
      "Loss on iteration 652 is: 0.3581298961173824\n",
      "Loss on iteration 653 is: 0.3581298961173824\n",
      "Loss on iteration 654 is: 0.35812989611738244\n",
      "Loss on iteration 655 is: 0.35812989611738255\n",
      "Loss on iteration 656 is: 0.35812989611738244\n",
      "Loss on iteration 657 is: 0.35812989611738244\n",
      "Loss on iteration 658 is: 0.3581298961173824\n",
      "Loss on iteration 659 is: 0.35812989611738255\n",
      "Loss on iteration 660 is: 0.35812989611738255\n",
      "Loss on iteration 661 is: 0.35812989611738244\n",
      "Loss on iteration 662 is: 0.35812989611738255\n",
      "Loss on iteration 663 is: 0.3581298961173826\n",
      "Loss on iteration 664 is: 0.3581298961173824\n",
      "Loss on iteration 665 is: 0.3581298961173824\n",
      "Loss on iteration 666 is: 0.35812989611738244\n",
      "Loss on iteration 667 is: 0.35812989611738244\n",
      "Loss on iteration 668 is: 0.35812989611738255\n",
      "Loss on iteration 669 is: 0.35812989611738255\n",
      "Loss on iteration 670 is: 0.35812989611738266\n",
      "Loss on iteration 671 is: 0.35812989611738255\n",
      "Loss on iteration 672 is: 0.35812989611738255\n",
      "Loss on iteration 673 is: 0.3581298961173826\n",
      "Loss on iteration 674 is: 0.3581298961173824\n",
      "Loss on iteration 675 is: 0.3581298961173826\n",
      "Loss on iteration 676 is: 0.35812989611738255\n",
      "Loss on iteration 677 is: 0.3581298961173824\n",
      "Loss on iteration 678 is: 0.35812989611738244\n",
      "Loss on iteration 679 is: 0.35812989611738255\n",
      "Loss on iteration 680 is: 0.35812989611738255\n",
      "Loss on iteration 681 is: 0.35812989611738244\n",
      "Loss on iteration 682 is: 0.35812989611738233\n",
      "Loss on iteration 683 is: 0.35812989611738233\n",
      "Loss on iteration 684 is: 0.35812989611738244\n",
      "Loss on iteration 685 is: 0.35812989611738244\n",
      "Loss on iteration 686 is: 0.35812989611738255\n",
      "Loss on iteration 687 is: 0.35812989611738244\n",
      "Loss on iteration 688 is: 0.35812989611738255\n",
      "Loss on iteration 689 is: 0.3581298961173826\n",
      "Loss on iteration 690 is: 0.35812989611738255\n",
      "Loss on iteration 691 is: 0.35812989611738255\n",
      "Loss on iteration 692 is: 0.35812989611738244\n",
      "Loss on iteration 693 is: 0.35812989611738244\n",
      "Loss on iteration 694 is: 0.3581298961173824\n",
      "Loss on iteration 695 is: 0.3581298961173824\n",
      "Loss on iteration 696 is: 0.35812989611738244\n",
      "Loss on iteration 697 is: 0.35812989611738244\n",
      "Loss on iteration 698 is: 0.35812989611738244\n",
      "Loss on iteration 699 is: 0.35812989611738255\n",
      "Loss on iteration 700 is: 0.35812989611738255\n",
      "Loss on iteration 701 is: 0.35812989611738255\n",
      "Loss on iteration 702 is: 0.3581298961173826\n",
      "Loss on iteration 703 is: 0.35812989611738255\n",
      "Loss on iteration 704 is: 0.35812989611738255\n",
      "Loss on iteration 705 is: 0.35812989611738255\n",
      "Loss on iteration 706 is: 0.35812989611738244\n",
      "Loss on iteration 707 is: 0.35812989611738255\n",
      "Loss on iteration 708 is: 0.35812989611738244\n",
      "Loss on iteration 709 is: 0.35812989611738266\n",
      "Loss on iteration 710 is: 0.3581298961173826\n",
      "Loss on iteration 711 is: 0.3581298961173826\n",
      "Loss on iteration 712 is: 0.35812989611738255\n",
      "Loss on iteration 713 is: 0.3581298961173826\n",
      "Loss on iteration 714 is: 0.35812989611738255\n",
      "Loss on iteration 715 is: 0.35812989611738255\n",
      "Loss on iteration 716 is: 0.35812989611738255\n",
      "Loss on iteration 717 is: 0.35812989611738255\n",
      "Loss on iteration 718 is: 0.35812989611738255\n",
      "Loss on iteration 719 is: 0.35812989611738255\n",
      "Loss on iteration 720 is: 0.35812989611738255\n",
      "Loss on iteration 721 is: 0.35812989611738255\n",
      "Loss on iteration 722 is: 0.35812989611738255\n",
      "Loss on iteration 723 is: 0.35812989611738255\n",
      "Loss on iteration 724 is: 0.35812989611738255\n",
      "Loss on iteration 725 is: 0.35812989611738255\n",
      "Loss on iteration 726 is: 0.35812989611738255\n",
      "Loss on iteration 727 is: 0.35812989611738255\n",
      "Loss on iteration 728 is: 0.35812989611738255\n",
      "Loss on iteration 729 is: 0.35812989611738255\n",
      "Loss on iteration 730 is: 0.35812989611738255\n",
      "Loss on iteration 731 is: 0.35812989611738255\n",
      "Loss on iteration 732 is: 0.35812989611738255\n",
      "Loss on iteration 733 is: 0.35812989611738255\n",
      "Loss on iteration 734 is: 0.35812989611738255\n",
      "Loss on iteration 735 is: 0.35812989611738255\n",
      "Loss on iteration 736 is: 0.35812989611738255\n",
      "Loss on iteration 737 is: 0.35812989611738255\n",
      "Loss on iteration 738 is: 0.35812989611738255\n",
      "Loss on iteration 739 is: 0.35812989611738255\n",
      "Loss on iteration 740 is: 0.35812989611738255\n",
      "Loss on iteration 741 is: 0.35812989611738255\n",
      "Loss on iteration 742 is: 0.35812989611738255\n",
      "Loss on iteration 743 is: 0.35812989611738255\n",
      "Loss on iteration 744 is: 0.35812989611738255\n",
      "Loss on iteration 745 is: 0.35812989611738255\n",
      "Loss on iteration 746 is: 0.35812989611738255\n",
      "Loss on iteration 747 is: 0.35812989611738255\n",
      "Loss on iteration 748 is: 0.35812989611738255\n",
      "Loss on iteration 749 is: 0.35812989611738255\n",
      "Loss on iteration 750 is: 0.35812989611738255\n",
      "Loss on iteration 751 is: 0.35812989611738255\n",
      "Loss on iteration 752 is: 0.35812989611738255\n",
      "Loss on iteration 753 is: 0.35812989611738255\n",
      "Loss on iteration 754 is: 0.35812989611738255\n",
      "Loss on iteration 755 is: 0.35812989611738255\n",
      "Loss on iteration 756 is: 0.35812989611738255\n",
      "Loss on iteration 757 is: 0.35812989611738255\n",
      "Loss on iteration 758 is: 0.35812989611738255\n",
      "Loss on iteration 759 is: 0.35812989611738255\n",
      "Loss on iteration 760 is: 0.35812989611738255\n",
      "Loss on iteration 761 is: 0.35812989611738255\n",
      "Loss on iteration 762 is: 0.35812989611738255\n",
      "Loss on iteration 763 is: 0.35812989611738255\n",
      "Loss on iteration 764 is: 0.35812989611738255\n",
      "Loss on iteration 765 is: 0.35812989611738255\n",
      "Loss on iteration 766 is: 0.35812989611738255\n",
      "Loss on iteration 767 is: 0.35812989611738255\n",
      "Loss on iteration 768 is: 0.35812989611738255\n",
      "Loss on iteration 769 is: 0.35812989611738255\n",
      "Loss on iteration 770 is: 0.35812989611738255\n",
      "Loss on iteration 771 is: 0.35812989611738255\n",
      "Loss on iteration 772 is: 0.35812989611738255\n",
      "Loss on iteration 773 is: 0.35812989611738255\n",
      "Loss on iteration 774 is: 0.35812989611738255\n",
      "Loss on iteration 775 is: 0.35812989611738255\n",
      "Loss on iteration 776 is: 0.35812989611738255\n",
      "Loss on iteration 777 is: 0.35812989611738255\n",
      "Loss on iteration 778 is: 0.35812989611738255\n",
      "Loss on iteration 779 is: 0.35812989611738255\n",
      "Loss on iteration 780 is: 0.35812989611738255\n",
      "Loss on iteration 781 is: 0.35812989611738255\n",
      "Loss on iteration 782 is: 0.35812989611738255\n",
      "Loss on iteration 783 is: 0.35812989611738255\n",
      "Loss on iteration 784 is: 0.35812989611738255\n",
      "Loss on iteration 785 is: 0.35812989611738255\n",
      "Loss on iteration 786 is: 0.35812989611738255\n",
      "Loss on iteration 787 is: 0.35812989611738255\n",
      "Loss on iteration 788 is: 0.35812989611738255\n",
      "Loss on iteration 789 is: 0.35812989611738255\n",
      "Loss on iteration 790 is: 0.35812989611738255\n",
      "Loss on iteration 791 is: 0.35812989611738255\n",
      "Loss on iteration 792 is: 0.35812989611738255\n",
      "Loss on iteration 793 is: 0.35812989611738255\n",
      "Loss on iteration 794 is: 0.35812989611738255\n",
      "Loss on iteration 795 is: 0.35812989611738255\n",
      "Loss on iteration 796 is: 0.35812989611738255\n",
      "Loss on iteration 797 is: 0.35812989611738255\n",
      "Loss on iteration 798 is: 0.35812989611738255\n",
      "Loss on iteration 799 is: 0.35812989611738255\n",
      "Loss on iteration 800 is: 0.35812989611738255\n",
      "Loss on iteration 801 is: 0.35812989611738255\n",
      "Loss on iteration 802 is: 0.35812989611738255\n",
      "Loss on iteration 803 is: 0.35812989611738255\n",
      "Loss on iteration 804 is: 0.35812989611738255\n",
      "Loss on iteration 805 is: 0.35812989611738255\n",
      "Loss on iteration 806 is: 0.35812989611738255\n",
      "Loss on iteration 807 is: 0.35812989611738255\n",
      "Loss on iteration 808 is: 0.35812989611738255\n",
      "Loss on iteration 809 is: 0.35812989611738255\n",
      "Loss on iteration 810 is: 0.35812989611738255\n",
      "Loss on iteration 811 is: 0.35812989611738255\n",
      "Loss on iteration 812 is: 0.35812989611738255\n",
      "Loss on iteration 813 is: 0.35812989611738255\n",
      "Loss on iteration 814 is: 0.35812989611738255\n",
      "Loss on iteration 815 is: 0.35812989611738255\n",
      "Loss on iteration 816 is: 0.35812989611738255\n",
      "Loss on iteration 817 is: 0.35812989611738255\n",
      "Loss on iteration 818 is: 0.35812989611738255\n",
      "Loss on iteration 819 is: 0.35812989611738255\n",
      "Loss on iteration 820 is: 0.35812989611738255\n",
      "Loss on iteration 821 is: 0.35812989611738255\n",
      "Loss on iteration 822 is: 0.35812989611738255\n",
      "Loss on iteration 823 is: 0.35812989611738255\n",
      "Loss on iteration 824 is: 0.35812989611738255\n",
      "Loss on iteration 825 is: 0.35812989611738255\n",
      "Loss on iteration 826 is: 0.35812989611738255\n",
      "Loss on iteration 827 is: 0.35812989611738255\n",
      "Loss on iteration 828 is: 0.35812989611738255\n",
      "Loss on iteration 829 is: 0.35812989611738255\n",
      "Loss on iteration 830 is: 0.35812989611738255\n",
      "Loss on iteration 831 is: 0.35812989611738255\n",
      "Loss on iteration 832 is: 0.35812989611738255\n",
      "Loss on iteration 833 is: 0.35812989611738255\n",
      "Loss on iteration 834 is: 0.35812989611738255\n",
      "Loss on iteration 835 is: 0.35812989611738255\n",
      "Loss on iteration 836 is: 0.35812989611738255\n",
      "Loss on iteration 837 is: 0.35812989611738255\n",
      "Loss on iteration 838 is: 0.35812989611738255\n",
      "Loss on iteration 839 is: 0.35812989611738255\n",
      "Loss on iteration 840 is: 0.35812989611738255\n",
      "Loss on iteration 841 is: 0.35812989611738255\n",
      "Loss on iteration 842 is: 0.35812989611738255\n",
      "Loss on iteration 843 is: 0.35812989611738255\n",
      "Loss on iteration 844 is: 0.35812989611738255\n",
      "Loss on iteration 845 is: 0.35812989611738255\n",
      "Loss on iteration 846 is: 0.35812989611738255\n",
      "Loss on iteration 847 is: 0.35812989611738255\n",
      "Loss on iteration 848 is: 0.35812989611738255\n",
      "Loss on iteration 849 is: 0.35812989611738255\n",
      "Loss on iteration 850 is: 0.35812989611738255\n",
      "Loss on iteration 851 is: 0.35812989611738255\n",
      "Loss on iteration 852 is: 0.35812989611738255\n",
      "Loss on iteration 853 is: 0.35812989611738255\n",
      "Loss on iteration 854 is: 0.35812989611738255\n",
      "Loss on iteration 855 is: 0.35812989611738255\n",
      "Loss on iteration 856 is: 0.35812989611738255\n",
      "Loss on iteration 857 is: 0.35812989611738255\n",
      "Loss on iteration 858 is: 0.35812989611738255\n",
      "Loss on iteration 859 is: 0.35812989611738255\n",
      "Loss on iteration 860 is: 0.35812989611738255\n",
      "Loss on iteration 861 is: 0.35812989611738255\n",
      "Loss on iteration 862 is: 0.35812989611738255\n",
      "Loss on iteration 863 is: 0.35812989611738255\n",
      "Loss on iteration 864 is: 0.35812989611738255\n",
      "Loss on iteration 865 is: 0.35812989611738255\n",
      "Loss on iteration 866 is: 0.35812989611738255\n",
      "Loss on iteration 867 is: 0.35812989611738255\n",
      "Loss on iteration 868 is: 0.35812989611738255\n",
      "Loss on iteration 869 is: 0.35812989611738255\n",
      "Loss on iteration 870 is: 0.35812989611738255\n",
      "Loss on iteration 871 is: 0.35812989611738255\n",
      "Loss on iteration 872 is: 0.35812989611738255\n",
      "Loss on iteration 873 is: 0.35812989611738255\n",
      "Loss on iteration 874 is: 0.35812989611738255\n",
      "Loss on iteration 875 is: 0.35812989611738255\n",
      "Loss on iteration 876 is: 0.35812989611738255\n",
      "Loss on iteration 877 is: 0.35812989611738255\n",
      "Loss on iteration 878 is: 0.35812989611738255\n",
      "Loss on iteration 879 is: 0.35812989611738255\n",
      "Loss on iteration 880 is: 0.35812989611738255\n",
      "Loss on iteration 881 is: 0.35812989611738255\n",
      "Loss on iteration 882 is: 0.35812989611738255\n",
      "Loss on iteration 883 is: 0.35812989611738255\n",
      "Loss on iteration 884 is: 0.35812989611738255\n",
      "Loss on iteration 885 is: 0.35812989611738255\n",
      "Loss on iteration 886 is: 0.35812989611738255\n",
      "Loss on iteration 887 is: 0.35812989611738255\n",
      "Loss on iteration 888 is: 0.35812989611738255\n",
      "Loss on iteration 889 is: 0.35812989611738255\n",
      "Loss on iteration 890 is: 0.35812989611738255\n",
      "Loss on iteration 891 is: 0.35812989611738255\n",
      "Loss on iteration 892 is: 0.35812989611738255\n",
      "Loss on iteration 893 is: 0.35812989611738255\n",
      "Loss on iteration 894 is: 0.35812989611738255\n",
      "Loss on iteration 895 is: 0.35812989611738255\n",
      "Loss on iteration 896 is: 0.35812989611738255\n",
      "Loss on iteration 897 is: 0.35812989611738255\n",
      "Loss on iteration 898 is: 0.35812989611738255\n",
      "Loss on iteration 899 is: 0.35812989611738255\n",
      "Loss on iteration 900 is: 0.35812989611738255\n",
      "Loss on iteration 901 is: 0.35812989611738255\n",
      "Loss on iteration 902 is: 0.35812989611738255\n",
      "Loss on iteration 903 is: 0.35812989611738255\n",
      "Loss on iteration 904 is: 0.35812989611738255\n",
      "Loss on iteration 905 is: 0.35812989611738255\n",
      "Loss on iteration 906 is: 0.35812989611738255\n",
      "Loss on iteration 907 is: 0.35812989611738255\n",
      "Loss on iteration 908 is: 0.35812989611738255\n",
      "Loss on iteration 909 is: 0.35812989611738255\n",
      "Loss on iteration 910 is: 0.35812989611738255\n",
      "Loss on iteration 911 is: 0.35812989611738255\n",
      "Loss on iteration 912 is: 0.35812989611738255\n",
      "Loss on iteration 913 is: 0.35812989611738255\n",
      "Loss on iteration 914 is: 0.35812989611738255\n",
      "Loss on iteration 915 is: 0.35812989611738255\n",
      "Loss on iteration 916 is: 0.35812989611738255\n",
      "Loss on iteration 917 is: 0.35812989611738255\n",
      "Loss on iteration 918 is: 0.35812989611738255\n",
      "Loss on iteration 919 is: 0.35812989611738255\n",
      "Loss on iteration 920 is: 0.35812989611738255\n",
      "Loss on iteration 921 is: 0.35812989611738255\n",
      "Loss on iteration 922 is: 0.35812989611738255\n",
      "Loss on iteration 923 is: 0.35812989611738255\n",
      "Loss on iteration 924 is: 0.35812989611738255\n",
      "Loss on iteration 925 is: 0.35812989611738255\n",
      "Loss on iteration 926 is: 0.35812989611738255\n",
      "Loss on iteration 927 is: 0.35812989611738255\n",
      "Loss on iteration 928 is: 0.35812989611738255\n",
      "Loss on iteration 929 is: 0.35812989611738255\n",
      "Loss on iteration 930 is: 0.35812989611738255\n",
      "Loss on iteration 931 is: 0.35812989611738255\n",
      "Loss on iteration 932 is: 0.35812989611738255\n",
      "Loss on iteration 933 is: 0.35812989611738255\n",
      "Loss on iteration 934 is: 0.35812989611738255\n",
      "Loss on iteration 935 is: 0.35812989611738255\n",
      "Loss on iteration 936 is: 0.35812989611738255\n",
      "Loss on iteration 937 is: 0.35812989611738255\n",
      "Loss on iteration 938 is: 0.35812989611738255\n",
      "Loss on iteration 939 is: 0.35812989611738255\n",
      "Loss on iteration 940 is: 0.35812989611738255\n",
      "Loss on iteration 941 is: 0.35812989611738255\n",
      "Loss on iteration 942 is: 0.35812989611738255\n",
      "Loss on iteration 943 is: 0.35812989611738255\n",
      "Loss on iteration 944 is: 0.35812989611738255\n",
      "Loss on iteration 945 is: 0.35812989611738255\n",
      "Loss on iteration 946 is: 0.35812989611738255\n",
      "Loss on iteration 947 is: 0.35812989611738255\n",
      "Loss on iteration 948 is: 0.35812989611738255\n",
      "Loss on iteration 949 is: 0.35812989611738255\n",
      "Loss on iteration 950 is: 0.35812989611738255\n",
      "Loss on iteration 951 is: 0.35812989611738255\n",
      "Loss on iteration 952 is: 0.35812989611738255\n",
      "Loss on iteration 953 is: 0.35812989611738255\n",
      "Loss on iteration 954 is: 0.35812989611738255\n",
      "Loss on iteration 955 is: 0.35812989611738255\n",
      "Loss on iteration 956 is: 0.35812989611738255\n",
      "Loss on iteration 957 is: 0.35812989611738255\n",
      "Loss on iteration 958 is: 0.35812989611738255\n",
      "Loss on iteration 959 is: 0.35812989611738255\n",
      "Loss on iteration 960 is: 0.35812989611738255\n",
      "Loss on iteration 961 is: 0.35812989611738255\n",
      "Loss on iteration 962 is: 0.35812989611738255\n",
      "Loss on iteration 963 is: 0.35812989611738255\n",
      "Loss on iteration 964 is: 0.35812989611738255\n",
      "Loss on iteration 965 is: 0.35812989611738255\n",
      "Loss on iteration 966 is: 0.35812989611738255\n",
      "Loss on iteration 967 is: 0.35812989611738255\n",
      "Loss on iteration 968 is: 0.35812989611738255\n",
      "Loss on iteration 969 is: 0.35812989611738255\n",
      "Loss on iteration 970 is: 0.35812989611738255\n",
      "Loss on iteration 971 is: 0.35812989611738255\n",
      "Loss on iteration 972 is: 0.35812989611738255\n",
      "Loss on iteration 973 is: 0.35812989611738255\n",
      "Loss on iteration 974 is: 0.35812989611738255\n",
      "Loss on iteration 975 is: 0.35812989611738255\n",
      "Loss on iteration 976 is: 0.35812989611738255\n",
      "Loss on iteration 977 is: 0.35812989611738255\n",
      "Loss on iteration 978 is: 0.35812989611738255\n",
      "Loss on iteration 979 is: 0.35812989611738255\n",
      "Loss on iteration 980 is: 0.35812989611738255\n",
      "Loss on iteration 981 is: 0.35812989611738255\n",
      "Loss on iteration 982 is: 0.35812989611738255\n",
      "Loss on iteration 983 is: 0.35812989611738255\n",
      "Loss on iteration 984 is: 0.35812989611738255\n",
      "Loss on iteration 985 is: 0.35812989611738255\n",
      "Loss on iteration 986 is: 0.35812989611738255\n",
      "Loss on iteration 987 is: 0.35812989611738255\n",
      "Loss on iteration 988 is: 0.35812989611738255\n",
      "Loss on iteration 989 is: 0.35812989611738255\n",
      "Loss on iteration 990 is: 0.35812989611738255\n",
      "Loss on iteration 991 is: 0.35812989611738255\n",
      "Loss on iteration 992 is: 0.35812989611738255\n",
      "Loss on iteration 993 is: 0.35812989611738255\n",
      "Loss on iteration 994 is: 0.35812989611738255\n",
      "Loss on iteration 995 is: 0.35812989611738255\n",
      "Loss on iteration 996 is: 0.35812989611738255\n",
      "Loss on iteration 997 is: 0.35812989611738255\n",
      "Loss on iteration 998 is: 0.35812989611738255\n",
      "Loss on iteration 999 is: 0.35812989611738255\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for input value 2: 3.0790077222568017\n"
     ]
    }
   ],
   "source": [
    "# Initial parameters\n",
    "w = 1\n",
    "b = 0\n",
    "lr = 0.1\n",
    "num_iter = 1000\n",
    "\n",
    "# Prepare the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X, Y, color='blue', label='Data')\n",
    "\n",
    "# Loop through iterations and plot the regression line for each step\n",
    "for i in range(num_iter):\n",
    "    Yp = predicting_Yp(X, w, b)\n",
    "    loss = calculate_loss(X, Y, Yp)\n",
    "    print(\"Loss on iteration\", i, \"is:\", loss)\n",
    "    # Update parameters for the next iteration\n",
    "    w, b = updating_param(X, Y, Yp, lr, w, b)\n",
    "\n",
    "# Plot the current regression line\n",
    "plt.plot(X, Yp, label=f'Iteration {i}')\n",
    "    \n",
    "# Add legend and labels\n",
    "plt.legend()\n",
    "plt.title(\"Progress of Linear Regression Over Iterations\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()\n",
    "\n",
    "# After training, test the prediction for value 2\n",
    "pred_value = test_value(0.1, w, b)\n",
    "print(\"Prediction for input value 2:\", pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.07900773]\n"
     ]
    }
   ],
   "source": [
    "# This is the Code from Sklearn library using built in function to compare out model with.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Reshape X to a 2D array with one column\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "print(model.predict([[0.1]]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
